{"entries":[],"headings":["the-data","our-first-language-model-from-scratch","our-language-model-in-pytorch","our-first-recurrent-neural-network","improving-the-rnn","maintaining-the-state-of-an-rnn","creating-more-signal","multilayer-rnns","the-model","exploding-or-disappearing-activations","lstm","building-an-lstm-from-scratch","training-a-language-model-using-lstms","regularizing-an-lstm","dropout","activation-regularization-and-temporal-activation-regularization","training-a-weight-tied-regularized-lstm","conclusion","questionnaire","further-research"]}