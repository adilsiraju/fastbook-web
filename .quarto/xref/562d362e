{"entries":[],"headings":["pixels-the-foundations-of-computer-vision","sidebar-tenacity-and-deep-learning","end-sidebar","first-try-pixel-similarity","numpy-arrays-and-pytorch-tensors","computing-metrics-using-broadcasting","stochastic-gradient-descent-sgd","calculating-gradients","stepping-with-a-learning-rate","an-end-to-end-sgd-example","step-1-initialize-the-parameters","step-2-calculate-the-predictions","step-3-calculate-the-loss","step-4-calculate-the-gradients","step-5-step-the-weights.","step-6-repeat-the-process","step-7-stop","summarizing-gradient-descent","the-mnist-loss-function","sigmoid","sgd-and-mini-batches","putting-it-all-together","creating-an-optimizer","adding-a-nonlinearity","going-deeper","jargon-recap","questionnaire","further-research"]}